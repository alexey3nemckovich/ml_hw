{
 "cells": [
  {
   "metadata": {
    "_uuid": "a603f52d84bce68c606a8ba684f08908e935d812"
   },
   "cell_type": "markdown",
   "source": [
    "## Types of Text Summarization Methods\n",
    "\n",
    "![Imgur](https://i.imgur.com/J5KyMBJ.png)\n"
   ]
  },
  {
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "collapsed": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "trusted": false
   },
   "cell_type": "markdown",
   "source": [
    "# Import Packages \n"
   ]
  },
  {
   "metadata": {
    "_kg_hide-input": true,
    "trusted": true,
    "_uuid": "2860a7dca6861d4a750915c770365e06a1408ce2"
   },
   "cell_type": "code",
   "source": [
    "import numpy as np # linear algebra\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from IPython.display import display\n",
    "import base64\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "from time import time\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import heapq\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "%matplotlib inline\n",
    "\n",
    "stopwords = stopwords.words('english')\n",
    "sns.set_context('notebook')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "_uuid": "5e261260676c97cde87e171b9b049763740f63aa"
   },
   "cell_type": "markdown",
   "source": [
    "# Import Dataset \n"
   ]
  },
  {
   "metadata": {
    "_kg_hide-input": true,
    "trusted": true,
    "_uuid": "a53b6190504ccf397dd408b5882cfed485046b3e"
   },
   "cell_type": "code",
   "source": [
    "reviews = pd.read_csv(\"\", usecols =['points', 'title', 'description'], encoding='latin1')\n",
    "reviews = reviews.dropna()\n",
    "reviews.head(15)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "_uuid": "489093d68a8c094167a77cdb7479c184b3e20e87"
   },
   "cell_type": "markdown",
   "source": [
    "# Text preprocessing"
   ]
  },
  {
   "metadata": {
    "_kg_hide-output": false,
    "trusted": true,
    "_uuid": "25fd7f9ae5fa5ca3efe698e99ba8e1631f7121a6",
    "_kg_hide-input": true
   },
   "cell_type": "code",
   "source": [
    "!python -m spacy download en_core_web_lg\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "def normalize_text(text):\n",
    "    tm1 = re.sub('<pre>.*?</pre>', '', text, flags=re.DOTALL)\n",
    "    tm2 = re.sub('<code>.*?</code>', '', tm1, flags=re.DOTALL)\n",
    "    tm3 = re.sub('<[^>]+>©', '', tm1, flags=re.DOTALL)\n",
    "    return tm3.replace(\"\\n\", \"\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "_uuid": "a69744aafbd96fad87b1433c0cd3d40fbd4f04d2",
    "_kg_hide-input": true
   },
   "cell_type": "code",
   "source": [
    "\n",
    "reviews['description_Cleaned_1'] = reviews['description'].apply(normalize_text)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "_kg_hide-input": true,
    "trusted": true,
    "_uuid": "d38a9fb0751391660bc33de4431ef2f2c521606b"
   },
   "cell_type": "code",
   "source": [
    "print('Before normalizing text-----\\n')\n",
    "print(reviews['description'][2])\n",
    "print('\\nAfter normalizing text-----\\n')\n",
    "print(reviews['description_Cleaned_1'][2])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "_uuid": "0875039d74a5dc0636bbfb2eb93efcf7278c1f47"
   },
   "cell_type": "markdown",
   "source": [
    "Ваши методы, подумайте до конца ли вы почистили датасет"
   ]
  },
  {
   "metadata": {
    "_kg_hide-input": true,
    "trusted": true,
    "_uuid": "64f118a88d5c7fb5fcf276f017fe6318b8b7c45e"
   },
   "cell_type": "code",
   "source": [
    "punctuations = '!\"#$%&\\'()*+,-/:;<=>?@[\\\\]^_`{|}~©'\n",
    "# Define function to cleanup text by removing personal pronouns, stopwords, and puncuation\n",
    "def cleanup_text(docs, logging=False):\n",
    "    texts = []\n",
    "    doc = nlp(docs, disable=['parser', 'ner'])\n",
    "    tokens = [tok.lemma_.lower().strip() for tok in doc if tok.lemma_ != '-PRON-']\n",
    "    tokens = [tok for tok in tokens if tok not in stopwords and tok not in punctuations]\n",
    "    tokens = ' '.join(tokens)\n",
    "    texts.append(tokens)\n",
    "    return pd.Series(texts)\n",
    "\n",
    "reviews['Description_Cleaned'] = reviews['description_Cleaned_1'].apply(lambda x: cleanup_text(x, False))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true,
    "_uuid": "e9d814a5a03b4063b9e67efc2c6cf330ec8fc443"
   },
   "cell_type": "code",
   "source": [
    "print('Reviews description with punctuatin and stopwords---\\n')\n",
    "print(reviews['description_Cleaned_1'][0])\n",
    "print('\\nReviews description after removing punctuation and stopwrods---\\n')\n",
    "print(reviews['Description_Cleaned'][0])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "_uuid": "4a925e4a30c7ace8cb844ddbbadb0bd2a848f596"
   },
   "cell_type": "markdown",
   "source": [
    "# Distribution of Points"
   ]
  },
  {
   "metadata": {
    "_kg_hide-input": true,
    "trusted": true,
    "_uuid": "e981d5761ded4aea90b302aa0cb0d6ac9ed7c27a"
   },
   "cell_type": "code",
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "_uuid": "1642a971b3a627e10884a150714963ef2333e72b"
   },
   "cell_type": "markdown",
   "source": [
    "# Analyze reviews description"
   ]
  },
  {
   "metadata": {
    "_kg_hide-input": true,
    "trusted": true,
    "_uuid": "e68dde499af6efa3a8a942b362b8b095a7fcace1"
   },
   "cell_type": "code",
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "_uuid": "7f24b07ce1634f1a568f67bb6fd4a881c12fa113"
   },
   "cell_type": "markdown",
   "source": [
    "Pipeline for summary using spacy or gensim:\n",
    "\n",
    "### 1 Convert Paragraphs to Sentences\n",
    "\n",
    "### 2 Text Preprocessing\n",
    "\n",
    "### 3 Tokenizing the Sentences\n",
    "\n",
    "### 4 Find Weighted Frequency of Occurrence\n",
    "\n",
    "### 5 Replace Words by Weighted Frequency in Original Sentences\n",
    "\n",
    "### 6 Sort Sentences in Descending Order of Sum"
   ]
  },
  {
   "metadata": {
    "_kg_hide-input": true,
    "trusted": true,
    "_uuid": "231232c4be343eb6c6812ca26069bc437c422be8"
   },
   "cell_type": "code",
   "source": [
    "def generate_summary(text_without_removing_dot, cleaned_text):\n",
    "    sample_text = ...\n",
    "    doc = nlp(sample_text)\n",
    "    sentence_list=[]\n",
    "    for idx, sentence in enumerate(doc.sents): \n",
    "        sentence_list.append(re.sub(r'[^\\w\\s]','',str(sentence)))\n",
    "\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "    word_frequencies = {}  \n",
    "    ...\n",
    "    maximum_frequncy = max(word_frequencies.values())\n",
    "\n",
    "\n",
    "    sentence_scores = {}  \n",
    "    ...\n",
    "\n",
    "    summary_sentences = heapq.nlargest(7, sentence_scores, key=sentence_scores.get)\n",
    "\n",
    "    summary = ' '.join(summary_sentences)\n",
    "    print(\"Original Text:\\n\")\n",
    "    print(text_without_removing_dot)\n",
    "    print('\\n\\nSummarized text:\\n')\n",
    "    print(summary)  "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "_kg_hide-input": true,
    "trusted": true,
    "_uuid": "716d14346ed32a3530b28ff69e656b304344c054"
   },
   "cell_type": "code",
   "source": [
    "generate_summary(reviews['description_Cleaned_1'][8], reviews['Description_Cleaned'][8])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "_kg_hide-input": true,
    "trusted": true,
    "_uuid": "6626cafc63770b6c170e956ec5bdbd0616424d7c"
   },
   "cell_type": "code",
   "source": [
    "generate_summary(reviews['description_Cleaned_1'][100], reviews['Description_Cleaned'][100])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "_kg_hide-input": true,
    "trusted": true,
    "_uuid": "f8b4740ed18aea47c70b34fcc993f518b443c330"
   },
   "cell_type": "code",
   "source": [
    "generate_summary(reviews['description_Cleaned_1'][500], reviews['Description_Cleaned'][500])"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
